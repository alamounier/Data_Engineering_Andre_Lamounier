# üèóÔ∏è Projeto de ETL com Airflow, Docker, Delta Lake e Arquitetura Medalh√£o

Este projeto implementa um pipeline de ETL utilizando Apache Airflow, PySpark, Docker e Delta Lake, estruturado em uma arquitetura de dados em camadas (Bronze, Silver e Gold). O objetivo √© orquestrar o processamento de dados da API Open Brewery em cont√™ineres separados para cada etapa do pipeline.

<div align="center">
  <img src="/imgs_png/arquitetura_projeto.png" alt="python" height="200">
</div>

---

## üîß Pr√© Requisitos

- **Docker instalado na m√°quina local**  
- üëâ [Download do JAR aws-java-sdk-bundle](https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.1026/aws-java-sdk-bundle-1.11.1026.jar) ‚Äî salve o arquivo na pasta `src/jars`

---

## üîß Tecnologias Utilizadas

- **Apache Airflow** (orquestra√ß√£o de workflows)
- **Apache Spark com Delta Lake** (processamento de dados com transa√ß√µes ACID)
- **Docker** (ambiente isolado para cada etapa de processamento)
- **Docker Compose** (gerenciamento de m√∫ltiplos servi√ßos)
- **Python 3**

---

## üß± Arquitetura Medalh√£o

A arquitetura √© dividida em tr√™s camadas:

- **Bronze**: coleta dados crus da API Open Brewery.
- **Silver**: limpa, transforma e particiona os dados por localiza√ß√£o.
- **Gold**: agrega dados para an√°lises, como a contagem de cervejarias por tipo e localidade.

---

## üìÅ Estrutura do Projeto

<img src="/imgs_png/estrutura_projeto.png" alt="python" height="300" /> 

## ‚öôÔ∏è Como executar
Siga os passos abaixo para rodar este projeto:

1. Copie o diret√≥rio do projeto para uma pasta local em seu computador.

2. Garanta que o arquivo `aws-java-sdk-bundle-1.11.1026.jar` esteja na pasta src/jars.

3. Abra o terminal e navegue at√© o diret√≥rio do projeto.

4. No diret√≥rio do projeto, crie a imagem do container do PySpark executando o seguinte comando: `docker build -t pyspark_image .`

5. Aguarde a execu√ß√£o do passo 4 e em seguida navegue at√© a pasta Airflow/dags/ e abra o arquivo brewery_etl_dag.py e altere todas os "sources" dos par√¢metros Mount das taks, conforme abaixo:
    
    - De: source=r"C:\Users\andre-lamounier\Desktop\airflow-docker\meu-projeto\src\outputs"
    - Para: source=r"[caminho da sua pasta outputs]"
    
    **Observa√ß√£o:** Se voc√™ utilizar a barra invertida \ no caminho do arquivo, adicione o r antes da string com o caminho. Caso utilize a barra normal /, basta remover o r.

6. Agora, acesse a pasta Airflow no terminal e, em seguida, crie o container do Airflow com o seguinte comando: `docker-compose up -d`


## üß† L√≥gica

O objetivo deste pipeline √© aproveitar as vantagens da engine Delta e da arquitetura Medalh√£o para garantir um processamento eficiente, mantendo o controle sobre o hist√≥rico de dados e a vers√£o mais recente para an√°lises.

Camada Bronze: Armazena os dados brutos provenientes das fontes, mantendo todas as vers√µes dos registros. Utilizando o Change Data Feed (CDF), √© poss√≠vel rastrear qualquer altera√ß√£o nos dados ao longo do tempo. Isso oferece um hist√≥rico completo de todas as mudan√ßas feitas nos dados de entrada.

Camada Silver: A partir dessa camada, o pipeline processa e transforma os dados para um formato mais adequado para an√°lise. A tabela da camada Silver ser√° sobrescrita a cada execu√ß√£o, garantindo que apenas a vers√£o mais recente dos dados seja mantida, o que economiza recursos de processamento. N√£o h√° necessidade de armazenar o hist√≥rico completo das altera√ß√µes, j√° que a camada Bronze j√° preserva essa informa√ß√£o.

Camada Gold: A camada Gold ser√° a tabela da camada silver em formato agregado, ideal para constru√ß√£o de dashboards e relat√≥rios para √°rea de neg√≥cios.

Vantagem do Versionamento: Caso seja necess√°rio recuperar vers√µes anteriores dos dados ou realizar auditoria, a camada Bronze com versionamento via Delta oferece essa flexibilidade. A camada Silver foca apenas na vers√£o mais atual, o que facilita a an√°lise e melhora a performance.

Esse modelo de arquitetura permite um equil√≠brio entre o controle total do hist√≥rico (na camada Bronze) e a efici√™ncia de processamento (na camada Silver), otimizando recursos e mantendo a flexibilidade para futuros ajustes ou auditorias.


