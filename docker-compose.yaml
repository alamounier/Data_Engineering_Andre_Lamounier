version: "3.8"

services:
  minio:
    image: minio/minio
    container_name: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    volumes:
      - minio-data:/data
    command: server /data --console-address ":9001"
    networks:
      - sparknet

  spark-job:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: spark-job
    depends_on:
      - minio
    networks:
      - sparknet

  airflow-webserver:
    image: apache/airflow:2.9.1-python3.9
    container_name: airflow-webserver
    restart: always
    depends_on:
      - airflow-scheduler
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    volumes:
      - ./dags:/opt/airflow/dags
      - airflow-data:/opt/airflow
    ports:
      - "8080:8080"
    command: webserver
    networks:
      - sparknet

  airflow-scheduler:
    image: apache/airflow:2.9.1-python3.9
    container_name: airflow-scheduler
    restart: always
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=sqlite:////opt/airflow/airflow.db
    volumes:
      - ./dags:/opt/airflow/dags
      - airflow-data:/opt/airflow
    command: scheduler
    networks:
      - sparknet

volumes:
  minio-data:
  airflow-data:
  
networks:
  sparknet:
    driver: bridge
