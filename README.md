# ğŸ—ï¸ Projeto de ETL com Airflow, Docker, Delta Lake e Arquitetura MedalhÃ£o

Este projeto implementa um pipeline de ETL utilizando Apache Airflow, PySpark, Docker e Delta Lake, estruturado em uma arquitetura de dados em camadas (Bronze, Silver e Gold). O objetivo Ã© orquestrar o processamento de dados da API Open Brewery em contÃªineres separados para cada etapa do pipeline.

---

## ğŸ”§ Tecnologias Utilizadas

- **Apache Airflow** (orquestraÃ§Ã£o de workflows)
- **Apache Spark com Delta Lake** (processamento de dados com transaÃ§Ãµes ACID)
- **Docker** (ambiente isolado para cada etapa de processamento)
- **Docker Compose** (gerenciamento de mÃºltiplos serviÃ§os)
- **Python 3**

---

## ğŸ§± Arquitetura MedalhÃ£o

A arquitetura Ã© dividida em trÃªs camadas:

- **Bronze**: coleta dados crus da API Open Brewery.
- **Silver**: limpa, transforma e particiona os dados por localizaÃ§Ã£o.
- **Gold**: agrega dados para anÃ¡lises, como a contagem de cervejarias por tipo e localidade.

---

## ğŸ“ Estrutura do Projeto


