# ğŸ—ï¸ Projeto de ETL com Airflow, Docker, Delta Lake e Arquitetura MedalhÃ£o

Este projeto implementa um pipeline de ETL utilizando Apache Airflow, PySpark, Docker e Delta Lake, estruturado em uma arquitetura de dados em camadas (Bronze, Silver e Gold). O objetivo Ã© orquestrar o processamento de dados da API Open Brewery em contÃªineres separados para cada etapa do pipeline.

<div align="center">
  <img src="/imgs_png/arquitetura_projeto.png" alt="python" height="200">
</div>

---

## ğŸ”§ PrÃ© Requisitos

- **Docker instalado na mÃ¡quina local**  
- ğŸ‘‰ [Download do JAR aws-java-sdk-bundle](https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.1026/aws-java-sdk-bundle-1.11.1026.jar) â€” salve o arquivo na pasta `src/jars`

---

## ğŸ”§ Tecnologias Utilizadas

- **Apache Airflow** (orquestraÃ§Ã£o de workflows)
- **Apache Spark com Delta Lake** (processamento de dados com transaÃ§Ãµes ACID)
- **Docker** (ambiente isolado para cada etapa de processamento)
- **Docker Compose** (gerenciamento de mÃºltiplos serviÃ§os)
- **Python 3**

---

## ğŸ§± Arquitetura MedalhÃ£o

A arquitetura Ã© dividida em trÃªs camadas:

- **Bronze**: coleta dados crus da API Open Brewery.
- **Silver**: limpa, transforma e particiona os dados por localizaÃ§Ã£o.
- **Gold**: agrega dados para anÃ¡lises, como a contagem de cervejarias por tipo e localidade.

---

## ğŸ“ Estrutura do Projeto

<img src="/imgs_png/estrutura_projeto.png" alt="python" height="300" /> 

## âš™ï¸ Como executar
Siga os passos abaixo para rodar este projeto:

1. Copie o diretÃ³rio do projeto para uma pasta local em seu computador.

2. Abra o terminal e navegue atÃ© o diretÃ³rio do projeto.

3. Garanta que o arquivo aws-java-sdk-bundle-1.11.1026.jar esteja na pasta src/jars.

4. Crie a imagem do container do PySpark executando o seguinte comando: **docker build -t pyspark_image .**

5. Aguarde a execuÃ§Ã£o do passo 4 e em seguida navegue atÃ© a pasta Airflow/dags/ e abra o arquivo brewery_etl_dag.py e altere todas os "sources" dos parÃ¢metros Mount das taks, conforme abaixo:
    
    - De: source=r"C:\Users\andre-lamounier\Desktop\airflow-docker\meu-projeto\src\outputs"
    - Para: source=r"[caminho da sua pasta outputs]"
    
    **ObservaÃ§Ã£o:** Se vocÃª utilizar a barra invertida \ no caminho do arquivo, adicione o r antes da string com o caminho. Caso utilize a barra normal /, basta remover o r.

6. Agora, acesse a pasta Airflow no terminal e, em seguida, crie o container do Airflow com o seguinte comando: **docker-compose up -d**


## ğŸ§  LÃ³gica

O objetivo deste pipeline Ã© aproveitar as vantagens da engine Delta e da arquitetura MedalhÃ£o para garantir um processamento eficiente, mantendo o controle sobre o histÃ³rico de dados e a versÃ£o mais recente para anÃ¡lises.

Camada Bronze: Armazena os dados brutos provenientes das fontes, mantendo todas as versÃµes dos registros. Utilizando o Change Data Feed (CDF), Ã© possÃ­vel rastrear qualquer alteraÃ§Ã£o nos dados ao longo do tempo. Isso oferece um histÃ³rico completo de todas as mudanÃ§as feitas nos dados de entrada.

Camada Silver: A partir dessa camada, o pipeline processa e transforma os dados para um formato mais adequado para anÃ¡lise. A tabela da camada Silver serÃ¡ sobrescrita a cada execuÃ§Ã£o, garantindo que apenas a versÃ£o mais recente dos dados seja mantida, o que economiza recursos de processamento. NÃ£o hÃ¡ necessidade de armazenar o histÃ³rico completo das alteraÃ§Ãµes, jÃ¡ que a camada Bronze jÃ¡ preserva essa informaÃ§Ã£o.

Camada Gold: A camada Gold serÃ¡ a tabela da camada silver em formato agregado, ideal para construÃ§Ã£o de dashboards e relatÃ³rios para Ã¡rea de negÃ³cios.

Vantagem do Versionamento: Caso seja necessÃ¡rio recuperar versÃµes anteriores dos dados ou realizar auditoria, a camada Bronze com versionamento via Delta oferece essa flexibilidade. A camada Silver foca apenas na versÃ£o mais atual, o que facilita a anÃ¡lise e melhora a performance.

Esse modelo de arquitetura permite um equilÃ­brio entre o controle total do histÃ³rico (na camada Bronze) e a eficiÃªncia de processamento (na camada Silver), otimizando recursos e mantendo a flexibilidade para futuros ajustes ou auditorias.


